{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52a52c8-e934-478f-8495-4c0e89d1f5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnunetv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a438035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet_raw: /nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/SK/TS_FineTuning/nnUNet_raw\n",
      "nnUNet_preprocessed: /nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/Xingyang_Cui/Data_Preprocessed\n",
      "nnUNet_results: /nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/SK/TS_FineTuning/nnUNet_results\n"
     ]
    }
   ],
   "source": [
    "#setting the path\n",
    "\n",
    "import os\n",
    "os.environ[\"nnUNet_raw\"] = \"/nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/SK/TS_FineTuning/nnUNet_raw\"\n",
    "os.environ[\"nnUNet_preprocessed\"] = \"/nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/Xingyang_Cui/Data_Preprocessed\"\n",
    "os.environ[\"nnUNet_results\"] = \"/nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/SK/TS_FineTuning/nnUNet_results\"  # 训练结果存放目录\n",
    "# =Check\n",
    "print(\"nnUNet_raw:\", os.environ.get(\"nnUNet_raw\"))\n",
    "print(\"nnUNet_preprocessed:\", os.environ.get(\"nnUNet_preprocessed\"))\n",
    "print(\"nnUNet_results:\", os.environ.get(\"nnUNet_results\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3315be7b",
   "metadata": {},
   "source": [
    "### 2.Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3edf3e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/cuixing/.local/bin/nnUNetv2_plan_and_preprocess\", line 8, in <module>\n",
      "    sys.exit(plan_and_preprocess_entry())\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/experiment_planning/plan_and_preprocess_entrypoints.py\", line 180, in plan_and_preprocess_entry\n",
      "    extract_fingerprints(args.d, args.fpe, args.npfp, args.verify_dataset_integrity, args.clean, args.verbose)\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 47, in extract_fingerprints\n",
      "    extract_fingerprint_dataset(d, fingerprint_extractor_class, num_processes, check_dataset_integrity, clean,\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/experiment_planning/plan_and_preprocess_api.py\", line 26, in extract_fingerprint_dataset\n",
      "    dataset_name = convert_id_to_dataset_name(dataset_id)\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/utilities/dataset_name_id_conversion.py\", line 48, in convert_id_to_dataset_name\n",
      "    raise RuntimeError(f\"Could not find a dataset with the ID {dataset_id}. Make sure the requested dataset ID \"\n",
      "RuntimeError: Could not find a dataset with the ID 1. Make sure the requested dataset ID exists and that nnU-Net knows where raw and preprocessed data are located (see Documentation - Installation). Here are your currently defined folders:\n",
      "nnUNet_preprocessed=/scratch/mdp-umtri_project_root/mdp-umtri_project1/cuixing/Data_Preprocessed\n",
      "nnUNet_results=/home/cuixing/Foot&Ankle/Results\n",
      "nnUNet_raw=/home/cuixing/Foot&Ankle/Raw_data\n",
      "If something is not right, adapt your environment variables.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['nnUNetv2_plan_and_preprocess', '-d', '001', '-pl', 'ExperimentPlanner', '-c', '3d_fullres', '-np', '8']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2710643/1352926450.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    529\u001b[0m                                      output=stdout, stderr=stderr)\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['nnUNetv2_plan_and_preprocess', '-d', '001', '-pl', 'ExperimentPlanner', '-c', '3d_fullres', '-np', '8']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "#no mirroring\n",
    "import subprocess\n",
    "\n",
    "command = [\n",
    "    \"nnUNetv2_plan_and_preprocess\",\n",
    "    \"-d\", \"001\",  # 指定数据集 ID\n",
    "    \"-pl\", \"ExperimentPlanner\", \n",
    "    \"-c\", \"3d_fullres\",  # 选择 3D full resolution \n",
    "    \"-np\", \"8\"  #cores\n",
    "]\n",
    "\n",
    "subprocess.run(command, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec011903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint extraction...\n",
      "Dataset072_TS_app_bones\n",
      "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIOWithReorient'> reader/writer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [06:28<00:00,  5.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment planning...\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.7725 0.7725 0.7725]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1616.50485437  543.68932039  543.68932039]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.795675 0.795675 0.795675]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1569.42218871  527.85370911  527.85370911]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.81954525 0.81954525 0.81954525]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1523.71086282  512.47932924  512.47932924]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.84413161 0.84413161 0.84413161]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1479.33093478  497.55274683  497.55274683]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.86945556 0.86945556 0.86945556]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1436.243626    483.06091926  483.06091926]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.89553922 0.89553922 0.89553922]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1394.41128738  468.99118374  468.99118374]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.9224054 0.9224054 0.9224054]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1353.79736639  455.33124635  455.33124635]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.95007756 0.95007756 0.95007756]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1314.36637513  442.06917122  442.06917122]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.97857989 0.97857989 0.97857989]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1276.08385935  429.19337011  429.19337011]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.00793728 1.00793728 1.00793728]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1238.9163683   416.69259234  416.69259234]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.0381754 1.0381754 1.0381754]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1202.83142554  404.5559149   404.5559149 ]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.06932067 1.06932067 1.06932067]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1167.79750052  392.77273291  392.77273291]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.10140029 1.10140029 1.10140029]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1133.78398109  381.3327504   381.3327504 ]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.13444229 1.13444229 1.13444229]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1100.76114669  370.22597126  370.22597126]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.16847556 1.16847556 1.16847556]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1068.70014242  359.44269054  359.44269054]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.20352983 1.20352983 1.20352983]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1037.5729538   348.97348596  348.97348596]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.23963572 1.23963572 1.23963572]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [1007.35238233  338.80920967  338.80920967]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.2768248 1.2768248 1.2768248]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [978.01202168 328.94098027 328.94098027]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.31512954 1.31512954 1.31512954]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [949.52623464 319.36017501 319.36017501]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.35458343 1.35458343 1.35458343]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [921.87013072 310.05842234 310.05842234]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.39522093 1.39522093 1.39522093]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [895.01954439 301.02759451 301.02759451]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.43707756 1.43707756 1.43707756]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [868.95101397 292.25980049 292.25980049]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.48018988 1.48018988 1.48018988]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [843.64176114 283.74737912 283.74737912]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.52459558 1.52459558 1.52459558]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [819.06967101 275.48289235 275.48289235]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.57033345 1.57033345 1.57033345]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [795.21327282 267.45911879 267.45911879]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.61744345 1.61744345 1.61744345]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [772.05172119 259.66904737 259.66904737]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.66596675 1.66596675 1.66596675]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [749.56477785 252.10587123 252.10587123]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.71594576 1.71594576 1.71594576]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [727.73279403 244.76298178 244.76298178]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.76742413 1.76742413 1.76742413]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [706.53669323 237.63396289 237.63396289]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.82044685 1.82044685 1.82044685]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [685.95795459 230.71258533 230.71258533]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.87506026 1.87506026 1.87506026]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [665.97859669 223.99280129 223.99280129]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.93131207 1.93131207 1.93131207]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [646.58116184 217.46873912 217.46873912]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.98925143 1.98925143 1.98925143]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [627.74870081 211.13469817 211.13469817]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [2.04892897 2.04892897 2.04892897]. \n",
      "Current patch size: (256, 160, 160). \n",
      "Current median shape: [609.46475807 204.98514386 204.98514386]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 22, 'patch_size': (640, 640), 'median_image_size_in_voxels': array([560., 560.]), 'spacing': array([0.75, 0.75]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.nibabel_reader_writer.NibabelIOWithReorient'> reader/writer\n",
      "3D lowres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetResEncUNetLPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (256, 160, 160), 'median_image_size_in_voxels': (609, 205, 205), 'spacing': array([2.04892897, 2.04892897, 2.04892897]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'}\n",
      "\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (256, 160, 160), 'median_image_size_in_voxels': array([1665.,  560.,  560.]), 'spacing': array([0.75, 0.75, 0.75]), 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_blocks_per_stage': (1, 3, 4, 6, 6, 6), 'n_conv_per_stage_decoder': (1, 1, 1, 1, 1), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Plans were saved to /nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/Xingyang_Cui/Data_Preprocessed/Dataset072_TS_app_bones/nnUNetResEncUNetLPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset072_TS_app_bones\n",
      "Configuration: 2d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 18/72 [37:43<1:41:28, 112.75s/it]"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# nnUNetv2_plan_and_preprocess\n",
    "env_vars = {\n",
    "    \"LC_ALL\": \"C.UTF-8\",\n",
    "    \"LANG\": \"C.UTF-8\"\n",
    "}\n",
    "\n",
    "command = [\n",
    "    \"nnUNetv2_plan_and_preprocess\",\n",
    "    \"-d\", \"072\",\n",
    "    \"-pl\", \"nnUNetPlannerResEncL\",\n",
    "    \"-np\", \"1\"\n",
    "]\n",
    "\n",
    "# 显示输出\n",
    "subprocess.run(command, env={**env_vars, **dict(**os.environ)}, text=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a33abaa",
   "metadata": {},
   "source": [
    "## 3.Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc600821",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"nnUNet_raw\"] = \"/nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/SK/TS_FineTuning/nnUNet_raw\"\n",
    "os.environ[\"nnUNet_preprocessed\"] = \"/nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/SK/TS_FineTuning/nnUNet_preprocessed\"\n",
    "os.environ[\"nnUNet_results\"] = \"/nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/SK/TS_FineTuning/nnUNet_results\"  # 训练结果存放目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1343bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-05-15 23:46:11.752032: do_dummy_2d_data_aug: False\n",
      "2025-05-15 23:46:11.772379: Using splits from existing split file: /nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/Xingyang_Cui/Data_Preprocessed/Dataset072_TS_app_bones/splits_final.json\n",
      "2025-05-15 23:46:11.777369: The split file contains 5 splits.\n",
      "2025-05-15 23:46:11.779271: Desired fold for training: 1\n",
      "2025-05-15 23:46:11.781276: This split has 57 training and 15 validation cases.\n",
      "using pin_memory on device 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuixing/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pin_memory on device 0\n",
      "2025-05-15 23:46:31.170556: Using torch.compile...\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [1665.0, 560.0, 560.0], 'spacing': [0.75, 0.75, 0.75], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.ResidualEncoderUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_blocks_per_stage': [1, 3, 4, 6, 6, 6], 'n_conv_per_stage_decoder': [1, 1, 1, 1, 1], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset072_TS_app_bones', 'plans_name': 'nnUNetResEncUNetLPlans', 'original_median_spacing_after_transp': [0.75, 0.75, 0.75], 'original_median_shape_after_transp': [1665, 560, 560], 'image_reader_writer': 'NibabelIOWithReorient', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'nnUNetPlannerResEncL', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 568.86452100881, 'median': 394.0174865722656, 'min': -3024.0, 'percentile_00_5': -85.0, 'percentile_99_5': 2067.0, 'std': 494.6805947060915}}} \n",
      "\n",
      "2025-05-15 23:46:33.319593: unpacking dataset...\n",
      "2025-05-15 23:46:45.356276: unpacking done...\n",
      "2025-05-15 23:46:45.383060: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-05-15 23:46:45.440510: \n",
      "2025-05-15 23:46:45.443422: Epoch 0\n",
      "2025-05-15 23:46:45.445988: Current learning rate: 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/cuixing/.local/bin/nnUNetv2_train\", line 8, in <module>\n",
      "    sys.exit(run_training_entry())\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/run/run_training.py\", line 275, in run_training_entry\n",
      "    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/run/run_training.py\", line 211, in run_training\n",
      "    nnunet_trainer.run_training()\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1370, in run_training\n",
      "    train_outputs.append(self.train_step(next(self.dataloader_train)))\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 999, in train_step\n",
      "    self.grad_scaler.scale(l).backward()\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/torch/_tensor.py\", line 581, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 347, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 768.00 MiB. GPU 0 has a total capacity of 11.77 GiB of which 41.50 MiB is free. Including non-PyTorch memory, this process has 11.72 GiB memory in use. Of the allocated memory 10.70 GiB is allocated by PyTorch, and 673.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "Exception in thread Thread-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 125, in results_loop\n",
      "    raise e\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 103, in results_loop\n",
      "    raise RuntimeError(\"One or more background workers are no longer alive. Exiting. Please check the \"\n",
      "RuntimeError: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message\n",
      "Exception in thread Thread-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/threading.py\", line 973, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/threading.py\", line 910, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 125, in results_loop\n",
      "    raise e\n",
      "  File \"/home/cuixing/.local/lib/python3.9/site-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 103, in results_loop\n",
      "    raise RuntimeError(\"One or more background workers are no longer alive. Exiting. Please check the \"\n",
      "RuntimeError: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['nnUNetv2_train', '072', '3d_fullres', '1', '-p', 'nnUNetResEncUNetLPlans', '-device', 'cuda'], returncode=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Augmentation\n",
    "import subprocess\n",
    "\n",
    "# Training\n",
    "train_command = [\n",
    "    \"nnUNetv2_train\",\n",
    "    \"072\", \"3d_fullres\", \"1\",\n",
    "    \"-p\", \"nnUNetResEncUNetLPlans\",\n",
    "    \"-device\", \"cuda\"\n",
    "]\n",
    "\n",
    "# Run\n",
    "subprocess.run(train_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8663f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "using port 39545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W515 23:52:06.705279523 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "[W515 23:52:06.706710747 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "[W515 23:52:06.708122192 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "[W515 23:52:07.794205225 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "[W515 23:52:07.795683428 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "[W515 23:52:07.797731323 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "[W515 23:52:07.814716344 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "[W515 23:52:07.816176018 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "[W515 23:52:07.817619294 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "[W515 23:52:07.132156820 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "[W515 23:52:07.133625095 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "[W515 23:52:07.135044614 socket.cpp:752] [c10d] The client socket cannot be initialized to connect to [localhost]:39545 (errno: 97 - Address family not supported by protocol).\n",
      "/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n",
      "/home/cuixing/.local/lib/python3.9/site-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am local rank 0. 4 GPUs are available. The world size is 4.Setting device to cuda\n",
      "worker 0 oversample 0.0\n",
      "worker 0 batch_size 1\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "2025-05-15 23:52:07.979965: do_dummy_2d_data_aug: False\n",
      "2025-05-15 23:52:08.003067: Using splits from existing split file: /nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/SK/TS_FineTuning/nnUNet_preprocessed/Dataset072_TS_app_bones/splits_final.json\n",
      "2025-05-15 23:52:08.006790: The split file contains 1 splits.\n",
      "2025-05-15 23:52:08.008694: Desired fold for training: 1\n",
      "2025-05-15 23:52:08.010838: INFO: You requested fold 1 for training but splits contain only 1 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "2025-05-15 23:52:08.013683: This random 80:20 split has 57 training and 15 validation cases.\n",
      "I am local rank 1. 4 GPUs are available. The world size is 4.Setting device to cuda\n",
      "worker 1 oversample 0.0\n",
      "worker 1 batch_size 1\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "do_dummy_2d_data_aug: False\n",
      "Using splits from existing split file: /nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/SK/TS_FineTuning/nnUNet_preprocessed/Dataset072_TS_app_bones/splits_final.json\n",
      "The split file contains 1 splits.\n",
      "Desired fold for training: 1\n",
      "INFO: You requested fold 1 for training but splits contain only 1 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "This random 80:20 split has 57 training and 15 validation cases.\n",
      "I am local rank 3. 4 GPUs are available. The world size is 4.Setting device to cuda\n",
      "worker 3 oversample 1.0\n",
      "worker 3 batch_size 1\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "do_dummy_2d_data_aug: False\n",
      "Using splits from existing split file: /nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/SK/TS_FineTuning/nnUNet_preprocessed/Dataset072_TS_app_bones/splits_final.json\n",
      "The split file contains 1 splits.\n",
      "Desired fold for training: 1\n",
      "INFO: You requested fold 1 for training but splits contain only 1 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "This random 80:20 split has 57 training and 15 validation cases.\n",
      "I am local rank 2. 4 GPUs are available. The world size is 4.Setting device to cuda\n",
      "worker 2 oversample 0.0\n",
      "worker 2 batch_size 1\n",
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "do_dummy_2d_data_aug: False\n",
      "Using splits from existing split file: /nfs/turbo/coe-mreedsensitive/Processing/Foot_and_Ankle/SK/TS_FineTuning/nnUNet_preprocessed/Dataset072_TS_app_bones/splits_final.json\n",
      "The split file contains 1 splits.\n",
      "Desired fold for training: 1\n",
      "INFO: You requested fold 1 for training but splits contain only 1 folds. I am now creating a random (but seeded) 80:20 split!\n",
      "This random 80:20 split has 57 training and 15 validation cases.\n",
      "using pin_memory on device 0\n",
      "using pin_memory on device 3\n",
      "using pin_memory on device 1\n",
      "using pin_memory on device 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuixing/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/cuixing/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/cuixing/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/home/cuixing/.local/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pin_memory on device 0\n",
      "2025-05-15 23:53:36.437602: Using torch.compile...\n",
      "\n",
      "This is the configuration used by this training:\n",
      "Configuration name: 3d_fullres\n",
      " {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [256, 96, 96], 'median_image_size_in_voxels': [1665.0, 560.0, 560.0], 'spacing': [0.75, 0.75, 0.75], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 1, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} \n",
      "\n",
      "These are the global plan.json settings:\n",
      " {'dataset_name': 'Dataset072_TS_app_bones', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.75, 0.75, 0.75], 'original_median_shape_after_transp': [1665, 560, 560], 'image_reader_writer': 'NibabelIOWithReorient', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 568.86452100881, 'median': 394.0174865722656, 'min': -3024.0, 'percentile_00_5': -85.0, 'percentile_99_5': 2067.0, 'std': 494.6805947060915}}} \n",
      "\n",
      "2025-05-15 23:53:44.502894: unpacking dataset...\n",
      "2025-05-15 23:53:57.992796: unpacking done...\n",
      "2025-05-15 23:53:58.021757: Unable to plot network architecture: nnUNet_compile is enabled!\n",
      "2025-05-15 23:53:58.103715: \n",
      "2025-05-15 23:53:58.107198: Epoch 0\n",
      "2025-05-15 23:53:58.110103: Current learning rate: 0.01\n",
      "2025-05-15 23:59:21.628150: train_loss 0.2766\n",
      "2025-05-15 23:59:21.707492: val_loss 0.1065\n",
      "2025-05-15 23:59:21.713724: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2025-05-15 23:59:21.721782: Epoch time: 323.53 s\n",
      "2025-05-15 23:59:21.728684: Yayy! New best EMA pseudo Dice: 0.0\n",
      "2025-05-15 23:59:25.350388: \n",
      "2025-05-15 23:59:25.353806: Epoch 1\n",
      "2025-05-15 23:59:25.356353: Current learning rate: 0.00999\n",
      "2025-05-16 00:02:27.148467: train_loss 0.1153\n",
      "2025-05-16 00:02:27.209345: val_loss 0.1137\n",
      "2025-05-16 00:02:27.215155: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0017, 0.0]\n",
      "2025-05-16 00:02:27.221526: Epoch time: 181.8 s\n",
      "2025-05-16 00:02:27.225743: Yayy! New best EMA pseudo Dice: 0.0\n",
      "2025-05-16 00:02:30.967291: \n",
      "2025-05-16 00:02:30.969640: Epoch 2\n",
      "2025-05-16 00:02:30.971901: Current learning rate: 0.00998\n",
      "2025-05-16 00:05:29.496326: train_loss 0.0893\n",
      "2025-05-16 00:05:29.540719: val_loss 0.085\n",
      "2025-05-16 00:05:29.566362: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2025-05-16 00:05:29.576096: Epoch time: 178.53 s\n",
      "2025-05-16 00:05:31.804126: \n",
      "2025-05-16 00:05:31.808656: Epoch 3\n",
      "2025-05-16 00:05:31.812731: Current learning rate: 0.00997\n",
      "2025-05-16 00:08:26.141352: train_loss 0.0781\n",
      "2025-05-16 00:08:26.168548: val_loss 0.0936\n",
      "2025-05-16 00:08:26.207242: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.001, 0.0]\n",
      "2025-05-16 00:08:26.217446: Epoch time: 174.34 s\n",
      "2025-05-16 00:08:26.225004: Yayy! New best EMA pseudo Dice: 0.0\n",
      "2025-05-16 00:08:29.917867: \n",
      "2025-05-16 00:08:29.920442: Epoch 4\n",
      "2025-05-16 00:08:29.922570: Current learning rate: 0.00996\n",
      "2025-05-16 00:11:22.990746: train_loss 0.068\n",
      "2025-05-16 00:11:23.049782: val_loss 0.0465\n",
      "2025-05-16 00:11:23.080992: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0]\n",
      "2025-05-16 00:11:23.089886: Epoch time: 173.07 s\n",
      "2025-05-16 00:11:25.314335: \n",
      "2025-05-16 00:11:25.316748: Epoch 5\n",
      "2025-05-16 00:11:25.318810: Current learning rate: 0.00995\n",
      "2025-05-16 00:14:43.761134: train_loss 0.0637\n",
      "2025-05-16 00:14:43.869838: val_loss 0.0583\n",
      "2025-05-16 00:14:43.883420: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0107, 0.0]\n",
      "2025-05-16 00:14:43.896862: Epoch time: 198.45 s\n",
      "2025-05-16 00:14:43.907777: Yayy! New best EMA pseudo Dice: 0.0001\n",
      "2025-05-16 00:14:47.440313: \n",
      "2025-05-16 00:14:47.442743: Epoch 6\n",
      "2025-05-16 00:14:47.444911: Current learning rate: 0.00995\n",
      "2025-05-16 00:17:54.372444: train_loss 0.0657\n",
      "2025-05-16 00:17:54.406652: val_loss 0.0583\n",
      "2025-05-16 00:17:54.456745: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0217, 0.0]\n",
      "2025-05-16 00:17:54.465002: Epoch time: 186.93 s\n",
      "2025-05-16 00:17:54.472811: Yayy! New best EMA pseudo Dice: 0.0001\n",
      "2025-05-16 00:17:58.251636: \n",
      "2025-05-16 00:17:58.254225: Epoch 7\n",
      "2025-05-16 00:17:58.256556: Current learning rate: 0.00994\n",
      "2025-05-16 00:20:59.193048: train_loss 0.0619\n",
      "2025-05-16 00:20:59.213297: val_loss 0.063\n",
      "2025-05-16 00:20:59.218476: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0379, 0.0]\n",
      "2025-05-16 00:20:59.231638: Epoch time: 180.94 s\n",
      "2025-05-16 00:20:59.242563: Yayy! New best EMA pseudo Dice: 0.0003\n",
      "2025-05-16 00:21:02.790640: \n",
      "2025-05-16 00:21:02.793156: Epoch 8\n",
      "2025-05-16 00:21:02.795657: Current learning rate: 0.00993\n",
      "2025-05-16 00:24:04.308750: train_loss 0.0581\n",
      "2025-05-16 00:24:04.353477: val_loss 0.0632\n",
      "2025-05-16 00:24:04.371728: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0166, 0.0]\n",
      "2025-05-16 00:24:04.377673: Epoch time: 181.52 s\n",
      "2025-05-16 00:24:04.386065: Yayy! New best EMA pseudo Dice: 0.0003\n",
      "2025-05-16 00:24:07.996650: \n",
      "2025-05-16 00:24:07.999150: Epoch 9\n",
      "2025-05-16 00:24:08.001248: Current learning rate: 0.00992\n",
      "2025-05-16 00:27:02.068278: train_loss 0.0543\n",
      "2025-05-16 00:27:02.089469: val_loss 0.0715\n",
      "2025-05-16 00:27:02.093180: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0187, 0.0]\n",
      "2025-05-16 00:27:02.102875: Epoch time: 174.07 s\n",
      "2025-05-16 00:27:02.105676: Yayy! New best EMA pseudo Dice: 0.0004\n",
      "2025-05-16 00:27:05.883390: \n",
      "2025-05-16 00:27:05.886198: Epoch 10\n",
      "2025-05-16 00:27:05.888326: Current learning rate: 0.00991\n",
      "2025-05-16 00:30:01.898104: train_loss 0.0503\n",
      "2025-05-16 00:30:01.928736: val_loss 0.0532\n",
      "2025-05-16 00:30:01.942526: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0576, 0.0]\n",
      "2025-05-16 00:30:01.995417: Epoch time: 176.02 s\n",
      "2025-05-16 00:30:02.003526: Yayy! New best EMA pseudo Dice: 0.0006\n",
      "2025-05-16 00:30:05.866451: \n",
      "2025-05-16 00:30:05.869427: Epoch 11\n",
      "2025-05-16 00:30:05.872008: Current learning rate: 0.0099\n",
      "2025-05-16 00:33:06.480139: train_loss 0.0427\n",
      "2025-05-16 00:33:06.602986: val_loss 0.0436\n",
      "2025-05-16 00:33:06.608313: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1649, 0.0]\n",
      "2025-05-16 00:33:06.615446: Epoch time: 180.61 s\n",
      "2025-05-16 00:33:06.624185: Yayy! New best EMA pseudo Dice: 0.0013\n",
      "2025-05-16 00:33:10.289680: \n",
      "2025-05-16 00:33:10.292167: Epoch 12\n",
      "2025-05-16 00:33:10.294304: Current learning rate: 0.00989\n",
      "2025-05-16 00:36:05.797134: train_loss 0.0396\n",
      "2025-05-16 00:36:05.821342: val_loss 0.027\n",
      "2025-05-16 00:36:05.825626: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.402, 0.0117]\n",
      "2025-05-16 00:36:05.828749: Epoch time: 175.51 s\n",
      "2025-05-16 00:36:05.836699: Yayy! New best EMA pseudo Dice: 0.0029\n",
      "2025-05-16 00:36:10.418212: \n",
      "2025-05-16 00:36:10.420576: Epoch 13\n",
      "2025-05-16 00:36:10.422842: Current learning rate: 0.00988\n",
      "2025-05-16 00:39:05.122025: train_loss 0.035\n",
      "2025-05-16 00:39:05.145436: val_loss 0.037\n",
      "2025-05-16 00:39:05.159416: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4508, 0.0068]\n",
      "2025-05-16 00:39:05.164026: Epoch time: 174.71 s\n",
      "2025-05-16 00:39:05.169735: Yayy! New best EMA pseudo Dice: 0.0046\n",
      "2025-05-16 00:39:08.889137: \n",
      "2025-05-16 00:39:08.891585: Epoch 14\n",
      "2025-05-16 00:39:08.893616: Current learning rate: 0.00987\n",
      "2025-05-16 00:42:12.907941: train_loss 0.0362\n",
      "2025-05-16 00:42:12.928311: val_loss 0.0277\n",
      "2025-05-16 00:42:12.941062: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.0235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4384, 0.1369]\n",
      "2025-05-16 00:42:12.947731: Epoch time: 184.02 s\n",
      "2025-05-16 00:42:12.961340: Yayy! New best EMA pseudo Dice: 0.0068\n",
      "2025-05-16 00:42:17.469852: \n",
      "2025-05-16 00:42:17.472457: Epoch 15\n",
      "2025-05-16 00:42:17.474563: Current learning rate: 0.00986\n",
      "2025-05-16 00:45:25.377702: train_loss 0.025\n",
      "2025-05-16 00:45:25.396338: val_loss 0.0442\n",
      "2025-05-16 00:45:25.404878: Pseudo dice [0.0, 0.0, 0.0, 0.0, 0.1564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.612, 0.0]\n",
      "2025-05-16 00:45:25.410846: Epoch time: 187.91 s\n",
      "2025-05-16 00:45:25.419439: Yayy! New best EMA pseudo Dice: 0.0094\n",
      "2025-05-16 00:45:29.102468: \n",
      "2025-05-16 00:45:29.105177: Epoch 16\n",
      "2025-05-16 00:45:29.107316: Current learning rate: 0.00986\n",
      "2025-05-16 00:48:34.225453: train_loss 0.0254\n",
      "2025-05-16 00:48:34.250929: val_loss 0.039\n",
      "2025-05-16 00:48:34.263815: Pseudo dice "
     ]
    }
   ],
   "source": [
    "#Mirroring\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "command = [\n",
    "    \"nnUNetv2_train\", \n",
    "    \"072\",  \n",
    "    \"3d_fullres\",  \n",
    "    \"1\",  \n",
    "    \"-tr\", \"nnUNetTrainer\",\n",
    "    #\"nnUNetTrainerNoMirroring\",  \n",
    "    \"-num_gpus\", \"4\",\n",
    "    #\"-max_epochs\", \"100\"  # max epoch\n",
    "]\n",
    "\n",
    "subprocess.run(command)\n",
    "# # 运行命令并确保实时输出\n",
    "# process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "\n",
    "# # 逐行读取并实时打印日志\n",
    "# for line in iter(process.stdout.readline, ''):\n",
    "#     sys.stdout.write(line)\n",
    "#     sys.stdout.flush()\n",
    "\n",
    "# # 等待进程结束\n",
    "# process.wait()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9550c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9e2ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b958d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6191cc1e",
   "metadata": {},
   "source": [
    "# Predicted the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce51711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#######################################################################\n",
      "Please cite the following paper when using nnU-Net:\n",
      "Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n",
      "#######################################################################\n",
      "\n",
      "There are 5 cases in the source folder\n",
      "I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n",
      "There are 5 cases that I would like to predict\n",
      "\n",
      "Predicting CF5017:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:12<00:00, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling and export\n",
      "done with CF5017\n",
      "\n",
      "Predicting CF5018:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:06<00:00, 21.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling and export\n",
      "done with CF5018\n",
      "\n",
      "Predicting CF5019:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [00:06<00:00, 21.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling and export\n",
      "done with CF5019\n",
      "\n",
      "Predicting CF6001:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:15<00:00, 21.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction on device was unsuccessful, probably due to a lack of memory. Moving results arrays to CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [01:12<00:00,  4.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling and export\n",
      "done with CF6001\n",
      "\n",
      "Predicting CF6002:\n",
      "perform_everything_on_device: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [00:10<00:00, 21.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending off prediction to background worker for resampling and export\n",
      "done with CF6002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['nnUNetv2_predict', '-i', '/home/cuixing/MDP/Data_Predict/Test_Data', '-o', '/home/cuixing/MDP/Data_Predict/Predicted_Result/100_Predict', '-d', '100', '-c', '3d_fullres', '-tr', 'nnUNetTrainerNoMirroring', '--disable_tta', '-f', '0', '-chk', 'checkpoint_best.pth'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "command = [\n",
    "    \"nnUNetv2_predict\",\n",
    "    \"-i\", \"/home/cuixing/MDP/Data_Predict/Test_Data\",\n",
    "    \"-o\", \"/home/cuixing/MDP/Data_Predict/Predicted_Result/50_Predict\",\n",
    "    \"-d\", \"100\",\n",
    "    \"-c\", \"3d_fullres\",\n",
    "    \"-tr\", \"nnUNetTrainerNoMirroring\",\n",
    "    \"--disable_tta\",\n",
    "    \"-f\", \"0\",\n",
    "    \"-chk\", \"checkpoint_best.pth\"\n",
    "]\n",
    "\n",
    "subprocess.run(command, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139d7fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db581f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769f22fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8aea3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38191e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a75b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcca8775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511ae34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a2d4de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 目录: /home/cuixing/MDP/Dataset100_TotalSegmentator_part_ribs\n",
      "  📄 文件: .DS_Store\n",
      "  📄 文件: dataset.json\n",
      "  📁 子目录: imagesTs\n",
      "  📁 子目录: imagesTr\n",
      "  📁 子目录: labelsTs\n",
      "  📁 子目录: labelsTr\n",
      "📂 目录: /home/cuixing/MDP/Dataset100_TotalSegmentator_part_ribs/imagesTs\n",
      "  📄 文件: s0006_0000.nii.gz\n",
      "📂 目录: /home/cuixing/MDP/Dataset100_TotalSegmentator_part_ribs/imagesTr\n",
      "  📄 文件: s0000_0000.nii.gz\n",
      "  📄 文件: s0013_0000.nii.gz\n",
      "  📄 文件: s0001_0000.nii.gz\n",
      "  📄 文件: s0002_0000.nii.gz\n",
      "  📄 文件: s0004_0000.nii.gz\n",
      "  📄 文件: s0003_0000.nii.gz\n",
      "📂 目录: /home/cuixing/MDP/Dataset100_TotalSegmentator_part_ribs/labelsTs\n",
      "  📄 文件: s0006.nii.gz\n",
      "📂 目录: /home/cuixing/MDP/Dataset100_TotalSegmentator_part_ribs/labelsTr\n",
      "  📄 文件: s0001.nii.gz\n",
      "  📄 文件: s0000.nii.gz\n",
      "  📄 文件: .DS_Store\n",
      "  📄 文件: s0004.nii.gz\n",
      "  📄 文件: s0002.nii.gz\n",
      "  📄 文件: s0013.nii.gz\n",
      "  📄 文件: s0003.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"/home/cuixing/MDP/Dataset100_TotalSegmentator_part_ribs\"  # 修改为你的目录\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    print(f\"📂 目录: {root}\")\n",
    "    for file in files:\n",
    "        print(f\"  📄 文件: {file}\")\n",
    "    for dir in dirs:\n",
    "        print(f\"  📁 子目录: {dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d455e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
